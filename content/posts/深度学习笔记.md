---
date: 2025-01-22T14:39:54+08:00
title: 笔记
description: 笔记
featured_image: /images/book.png
images:
  - /images/book.png
tags:
  - tutorial
  - DL
categories: Tutorials
---
# 神经网络
## 基础的模型和算法

### M-P模型
以下是一个简单的 m-P 神经网络模型（McCulloch-Pitts 模型）的 C 语言示例代码。这个代码实现了一个二输入单输出的神经元逻辑门（如 AND 门）：

```c
#include <stdio.h>

// 定义激活函数
int activation_function(int sum) {
    return sum >= 2 ? 1 : 0;  // 阈值为2，类似AND门
}

int main() {
    // 定义输入和权重
    int inputs[2];     // 两个输入
    int weights[2] = {1, 1}; // 权重
    int threshold = 2; // 阈值

    // 输入提示
    printf("请输入两个输入(0或1):\n");
    for (int i = 0; i < 2; i++) {
        printf("输入%d: ", i + 1);
        scanf("%d", &inputs[i]);
        if (inputs[i] != 0 && inputs[i] != 1) {
            printf("无效输入，请输入0或1。\n");
            return 1;
        }
    }

    // 计算加权和
    int sum = 0;
    for (int i = 0; i < 2; i++) {
        sum += inputs[i] * weights[i];
    }

    // 使用激活函数计算输出
    int output = activation_function(sum);

    // 输出结果
    printf("神经元输出: %d\n", output);

    return 0;
}
```

#### 代码说明

1. **激活函数**：
    
    - `activation_function(int sum)` 根据加权和是否超过阈值，决定输出是 `1`（激活）还是 `0`（未激活）。
    - 这里的逻辑是 `sum >= 2`，类似于 AND 门的逻辑。
2. **输入和权重**：
    
    - 用户输入两个值（`0` 或 `1`）。
    - 权重设置为 `[1, 1]`，表示每个输入的权重相同。
3. **加权和**：
    
    - 计算公式为 `sum += inputs[i] * weights[i]`。
4. **输出**：
    
    - 使用激活函数决定最终输出。

#### 示例运行

输入两个值 `1` 和 `1`：

```
请输入两个输入(0或1):
输入1: 1
输入2: 1
神经元输出: 1
```

输入两个值 `1` 和 `0`：

```
请输入两个输入(0或1):
输入1: 1
输入2: 0
神经元输出: 0
```

此代码可扩展为更多输入、复杂逻辑的神经网络。如果需要更复杂的 m-P 模型（例如多层结构），可以进一步增加神经元和连接逻辑。

---
### 改进后的M-P模型
下面是一个改进后的 McCulloch-Pitts (m-P) 模型的 C 语言实现，可以支持任意数量的输入、权重和阈值，使其适用于不同的逻辑门或神经元的实现：

```c
#include <stdio.h>
#include <stdlib.h>

// 定义激活函数
int activation_function(int sum, int threshold) {
    return sum >= threshold ? 1 : 0;  // 阈值判定
}

// m-P 模型实现
int m_p_model(int *inputs, int *weights, int num_inputs, int threshold) {
    int sum = 0;
    for (int i = 0; i < num_inputs; i++) {
        sum += inputs[i] * weights[i]; // 计算加权和
    }
    return activation_function(sum, threshold); // 返回激活函数输出
}

int main() {
    int num_inputs;
    
    // 动态输入个数
    printf("请输入输入的数量: ");
    scanf("%d", &num_inputs);
    if (num_inputs <= 0) {
        printf("输入数量必须大于0。\n");
        return 1;
    }

    // 分配动态数组
    int *inputs = (int *)malloc(num_inputs * sizeof(int));
    int *weights = (int *)malloc(num_inputs * sizeof(int));
    if (inputs == NULL || weights == NULL) {
        printf("内存分配失败。\n");
        return 1;
    }

    // 获取输入值
    printf("请输入 %d 个输入值(0或1):\n", num_inputs);
    for (int i = 0; i < num_inputs; i++) {
        printf("输入%d: ", i + 1);
        scanf("%d", &inputs[i]);
        if (inputs[i] != 0 && inputs[i] != 1) {
            printf("无效输入，请输入0或1。\n");
            free(inputs);
            free(weights);
            return 1;
        }
    }

    // 获取权重值
    printf("请输入 %d 个权重值:\n", num_inputs);
    for (int i = 0; i < num_inputs; i++) {
        printf("权重%d: ", i + 1);
        scanf("%d", &weights[i]);
    }

    // 获取阈值
    int threshold;
    printf("请输入阈值: ");
    scanf("%d", &threshold);

    // 调用 m-p 模型
    int output = m_p_model(inputs, weights, num_inputs, threshold);

    // 输出结果
    printf("神经元输出: %d\n", output);

    // 释放内存
    free(inputs);
    free(weights);

    return 0;
}
```

#### 代码说明

1. **泛化设计**：
    
    - 支持任意数量的输入，通过动态分配数组 (`malloc`) 来处理 `inputs` 和 `weights`。
    - 用户可以指定输入数量、每个输入值、每个权重值，以及阈值。
2. **灵活性**：
    
    - 可以轻松调整权重和阈值以实现不同的逻辑门。例如，设置 `weights = {1, 1}` 和 `threshold = 2` 是 AND 门，`threshold = 1` 是 OR 门。
3. **m_p_model 函数**：
    
    - 独立封装了 m-p 模型的逻辑，输入为输入数组、权重数组、输入数量和阈值，输出为激活结果。
4. **激活函数**：
    
    - 灵活的阈值比较，可根据具体需求调整。

---

#### 示例运行

##### 示例 1：实现 AND 门

输入：

```
请输入输入的数量: 2
请输入 2 个输入值(0或1):
输入1: 1
输入2: 1
请输入 2 个权重值:
权重1: 1
权重2: 1
请输入阈值: 2
```

输出：

```
神经元输出: 1
```

##### 示例 2：实现 OR 门

输入：

```
请输入输入的数量: 2
请输入 2 个输入值(0或1):
输入1: 1
输入2: 0
请输入 2 个权重值:
权重1: 1
权重2: 1
请输入阈值: 1
```

输出：

```
神经元输出: 1
```

##### 示例 3：自定义

输入：

```
请输入输入的数量: 3
请输入 3 个输入值(0或1):
输入1: 1
输入2: 1
输入3: 0
请输入 3 个权重值:
权重1: 2
权重2: 1
权重3: 1
请输入阈值: 3
```

输出：

```
神经元输出: 1
```

---
### 感知机
以下是一个简单的感知机 (Perceptron) 的 C 语言实现。感知机是一种二分类模型，它使用输入的加权和与偏置来计算输出，并通过权重的更新进行学习。

#### 示例代码

```c
#include <stdio.h>
#include <stdlib.h>

// 激活函数（阶跃函数）
int activation_function(float weighted_sum) {
    return weighted_sum >= 0 ? 1 : 0;  // 阈值为0
}

// 感知机模型
void perceptron_train(float **inputs, int *labels, float *weights, float *bias, int num_samples, int num_features, float learning_rate, int epochs) {
    for (int epoch = 0; epoch < epochs; epoch++) {
        printf("Epoch %d:\n", epoch + 1);
        for (int i = 0; i < num_samples; i++) {
            // 计算加权和
            float weighted_sum = *bias;
            for (int j = 0; j < num_features; j++) {
                weighted_sum += inputs[i][j] * weights[j];
            }

            // 预测值
            int prediction = activation_function(weighted_sum);

            // 计算误差
            int error = labels[i] - prediction;

            // 更新权重和偏置
            for (int j = 0; j < num_features; j++) {
                weights[j] += learning_rate * error * inputs[i][j];
            }
            *bias += learning_rate * error;

            // 输出权重和偏置
            printf("  样本 %d: 更新后权重 = [", i + 1);
            for (int j = 0; j < num_features; j++) {
                printf("%.2f%s", weights[j], j == num_features - 1 ? "" : ", ");
            }
            printf("], 偏置 = %.2f\n", *bias);
        }
        printf("\n");
    }
}

int main() {
    int num_samples = 4;      // 样本数量
    int num_features = 2;     // 每个样本的特征数量
    float learning_rate = 0.1; // 学习率
    int epochs = 10;          // 训练轮数

    // 训练数据 (逻辑与AND操作)
    float training_inputs[4][2] = {
        {0, 0},
        {0, 1},
        {1, 0},
        {1, 1}
    };
    int training_labels[4] = {0, 0, 0, 1}; // AND操作的标签

    // 转换为指针形式
    float *inputs[4];
    for (int i = 0; i < 4; i++) {
        inputs[i] = training_inputs[i];
    }

    // 初始化权重和偏置
    float weights[2] = {0.0, 0.0}; // 初始权重为0
    float bias = 0.0;              // 初始偏置为0

    // 训练感知机
    perceptron_train(inputs, training_labels, weights, &bias, num_samples, num_features, learning_rate, epochs);

    // 测试感知机
    printf("测试感知机:\n");
    for (int i = 0; i < num_samples; i++) {
        float weighted_sum = bias;
        for (int j = 0; j < num_features; j++) {
            weighted_sum += training_inputs[i][j] * weights[j];
        }
        int prediction = activation_function(weighted_sum);
        printf("  输入: [%.1f, %.1f], 预测: %d, 标签: %d\n",
               training_inputs[i][0], training_inputs[i][1], prediction, training_labels[i]);
    }

    return 0;
}
```

---

#### 代码说明

1. **激活函数**:
    
    - 使用阶跃函数作为激活函数，若加权和大于等于 0 则输出 `1`，否则输出 `0`。
2. **训练数据**:
    
    - 使用逻辑与 (`AND`) 的数据集，输入为 `[0, 0]`、`[0, 1]`、`[1, 0]`、`[1, 1]`，标签为 `[0, 0, 0, 1]`。
3. **训练过程**:
    
    - 逐个样本计算加权和。
    - 通过误差 (`error = label - prediction`) 更新权重和偏置：
        - 权重更新公式: `weights[j] += learning_rate * error * inputs[i][j]`
        - 偏置更新公式: `bias += learning_rate * error`
4. **测试过程**:
    
    - 使用训练后的权重和偏置，预测每个样本的输出，并与标签对比。

---

#### 示例运行结果

输出会随着每轮训练更新权重和偏置：

##### 训练过程：

```
Epoch 1:
  样本 1: 更新后权重 = [0.00, 0.00], 偏置 = 0.00
  样本 2: 更新后权重 = [0.00, 0.00], 偏置 = 0.00
  样本 3: 更新后权重 = [0.10, 0.00], 偏置 = 0.00
  样本 4: 更新后权重 = [0.10, 0.10], 偏置 = 0.10

...

Epoch 10:
  样本 1: 更新后权重 = [0.10, 0.10], 偏置 = -0.10
  样本 2: 更新后权重 = [0.10, 0.10], 偏置 = -0.10
  样本 3: 更新后权重 = [0.10, 0.10], 偏置 = -0.10
  样本 4: 更新后权重 = [0.10, 0.10], 偏置 = -0.10
```

##### 测试过程：

```
测试感知机:
  输入: [0.0, 0.0], 预测: 0, 标签: 0
  输入: [0.0, 1.0], 预测: 0, 标签: 0
  输入: [1.0, 0.0], 预测: 0, 标签: 0
  输入: [1.0, 1.0], 预测: 1, 标签: 1
```

---

#### 优化方向

- 将代码扩展为多分类任务。
- 增加支持浮点特征的输入。
- 使用动态数组进一步泛化输入数据的规模。
---
### 优化后的感知机实现

以下是经过优化后的感知机代码，实现了以下功能：

1. 支持多分类任务。
2. 支持浮点特征输入。
3. 使用动态数组泛化输入数据的规模。

优化后的代码更通用，适用于任意特征维度和类别数量的场景。

---

#### 优化后的代码

```c
#include <stdio.h>
#include <stdlib.h>
#include <math.h>

// 激活函数：返回预测类别（多分类通过比较加权和最大值实现）
int activation_function(float *weighted_sum, int num_classes) {
    int max_index = 0;
    float max_value = weighted_sum[0];
    for (int i = 1; i < num_classes; i++) {
        if (weighted_sum[i] > max_value) {
            max_value = weighted_sum[i];
            max_index = i;
        }
    }
    return max_index;
}

// 感知机训练函数
void perceptron_train(float **inputs, int *labels, float **weights, float *biases,
                      int num_samples, int num_features, int num_classes, float learning_rate, int epochs) {
    for (int epoch = 0; epoch < epochs; epoch++) {
        printf("Epoch %d:\n", epoch + 1);
        for (int i = 0; i < num_samples; i++) {
            // 计算每个类别的加权和
            float *weighted_sum = (float *)calloc(num_classes, sizeof(float));
            for (int c = 0; c < num_classes; c++) {
                weighted_sum[c] = biases[c];
                for (int j = 0; j < num_features; j++) {
                    weighted_sum[c] += inputs[i][j] * weights[c][j];
                }
            }

            // 预测类别
            int prediction = activation_function(weighted_sum, num_classes);

            // 计算误差并更新权重和偏置
            if (labels[i] != prediction) {
                for (int j = 0; j < num_features; j++) {
                    // 正确类别权重更新
                    weights[labels[i]][j] += learning_rate * inputs[i][j];
                    // 错误类别权重更新
                    weights[prediction][j] -= learning_rate * inputs[i][j];
                }
                // 更新偏置
                biases[labels[i]] += learning_rate;
                biases[prediction] -= learning_rate;
            }

            // 输出权重和偏置
            printf("  样本 %d: 权重更新后:\n", i + 1);
            for (int c = 0; c < num_classes; c++) {
                printf("    类别 %d: 权重 = [", c);
                for (int j = 0; j < num_features; j++) {
                    printf("%.2f%s", weights[c][j], j == num_features - 1 ? "" : ", ");
                }
                printf("], 偏置 = %.2f\n", biases[c]);
            }
            free(weighted_sum);
        }
        printf("\n");
    }
}

// 主函数
int main() {
    int num_samples = 6;       // 样本数量
    int num_features = 2;      // 每个样本的特征数量
    int num_classes = 3;       // 分类数量
    float learning_rate = 0.1; // 学习率
    int epochs = 10;           // 训练轮数

    // 训练数据（3类数据：0, 1, 2）
    float training_inputs[6][2] = {
        {1.0, 1.0}, {1.5, 2.0}, {2.0, 1.5},  // 类别 0
        {-1.0, -1.0}, {-1.5, -2.0}, {-2.0, -1.5} // 类别 1 和 2
    };
    int training_labels[6] = {0, 0, 0, 1, 2, 1};

    // 转换为指针形式
    float **inputs = (float **)malloc(num_samples * sizeof(float *));
    for (int i = 0; i < num_samples; i++) {
        inputs[i] = training_inputs[i];
    }

    // 动态分配权重和偏置
    float **weights = (float **)malloc(num_classes * sizeof(float *));
    for (int i = 0; i < num_classes; i++) {
        weights[i] = (float *)calloc(num_features, sizeof(float)); // 初始化为0
    }
    float *biases = (float *)calloc(num_classes, sizeof(float)); // 偏置初始化为0

    // 训练感知机
    perceptron_train(inputs, training_labels, weights, biases, num_samples, num_features, num_classes, learning_rate, epochs);

    // 测试感知机
    printf("测试感知机:\n");
    for (int i = 0; i < num_samples; i++) {
        float *weighted_sum = (float *)calloc(num_classes, sizeof(float));
        for (int c = 0; c < num_classes; c++) {
            weighted_sum[c] = biases[c];
            for (int j = 0; j < num_features; j++) {
                weighted_sum[c] += inputs[i][j] * weights[c][j];
            }
        }
        int prediction = activation_function(weighted_sum, num_classes);
        printf("  输入: [%.2f, %.2f], 预测类别: %d, 实际类别: %d\n",
               inputs[i][0], inputs[i][1], prediction, training_labels[i]);
        free(weighted_sum);
    }

    // 释放动态内存
    for (int i = 0; i < num_classes; i++) {
        free(weights[i]);
    }
    free(weights);
    free(biases);
    free(inputs);

    return 0;
}
```

---

#### 改进点说明

1. **多分类支持**:
    
    - 每个类别都有一组权重和一个偏置。
    - 使用所有类别的加权和，预测时选择加权和最大的类别。
2. **浮点特征支持**:
    
    - 输入特征使用 `float` 类型，支持更精确的数据。
3. **动态数组**:
    
    - 样本、权重和偏置使用动态分配内存，使得代码能够处理任意数量的样本和特征。

---

#### 测试运行结果

##### 示例输入：

训练数据为：

```plaintext
类别 0: [1.0, 1.0], [1.5, 2.0], [2.0, 1.5]
类别 1: [-1.0, -1.0], [-1.5, -2.0]
类别 2: [-2.0, -1.5]
```

##### 示例输出：

```plaintext
Epoch 1:
  样本 1: 权重更新后:
    类别 0: 权重 = [0.10, 0.10], 偏置 = 0.10
    类别 1: 权重 = [0.00, 0.00], 偏置 = 0.00
    类别 2: 权重 = [0.00, 0.00], 偏置 = 0.00

...
测试感知机:
  输入: [1.00, 1.00], 预测类别: 0, 实际类别: 0
  输入: [-1.50, -2.00], 预测类别: 1, 实际类别: 1
```

---

#### 优化后优势

- **可扩展性**: 支持任意类别数和特征数，适应多分类任务。
- **动态内存**: 更灵活处理大规模数据。
- **高可读性**: 分步骤组织清晰易懂，便于理解。
### 多层感知机

### 误差反向传播算法

### 误差函数和激活函数

### 似然函数

### 随机梯度下降法
